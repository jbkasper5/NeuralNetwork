// INPUT TOPOGRAPHY IN ORDER OF NEURONS IN INPUT LAYER TO NEURONS IN OUTPUT LAYER
16,10,10,1
// INPUT ACTIVATION FUNCTION PER LAYER LAYOUT: relu, sigmoid, tanh, or leakyrelu
relu,relu,sigmoid
